{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\\\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "from src.data.make_dataset import CRCHistoPhenotypes_Patch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.noise import GaussianNoise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CRCHistoPhenotypes_Patch(patch_size=(27,27))\n",
    "X, y = dataset.load_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(y)\n",
    "y = labelencoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22444"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 4\n",
    "epochs = 200\n",
    "data_augmentation = False\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_CRCPatches_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y, random_state=42)\n",
    "len_X_train = len(X_train)\n",
    "X_train = np.concatenate(X_train, axis=0).reshape((len_X_train, )+X[0].shape)\n",
    "\n",
    "len_X_test = len(X_test)\n",
    "X_test = np.concatenate(X_test, axis=0).reshape((len_X_test, )+X[0].shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Keras Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GaussianNoise(stddev=0.1, input_shape=(27, 27, 3)))\n",
    "model.add(Convolution2D(filters=32, kernel_size=(7, 7), activation='relu', input_shape=(27, 27, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Convolution2D(filters=48, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Convolution2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(4, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 15037 samples, validate on 7407 samples\n",
      "Epoch 1/200\n",
      "15037/15037 [==============================] - 7s - loss: 1.3222 - acc: 0.3700 - val_loss: 1.1268 - val_acc: 0.5449\n",
      "Epoch 2/200\n",
      "15037/15037 [==============================] - 3s - loss: 1.0899 - acc: 0.5475 - val_loss: 0.9208 - val_acc: 0.6640\n",
      "Epoch 3/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.9219 - acc: 0.6441 - val_loss: 0.9239 - val_acc: 0.6467\n",
      "Epoch 4/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.8764 - acc: 0.6627 - val_loss: 0.8313 - val_acc: 0.6784\n",
      "Epoch 5/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.8489 - acc: 0.6771 - val_loss: 0.8944 - val_acc: 0.6468\n",
      "Epoch 6/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.8246 - acc: 0.6832 - val_loss: 0.7947 - val_acc: 0.6980\n",
      "Epoch 7/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.8124 - acc: 0.6869 - val_loss: 0.7632 - val_acc: 0.7027\n",
      "Epoch 8/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.8035 - acc: 0.6952 - val_loss: 0.8142 - val_acc: 0.6831\n",
      "Epoch 9/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7914 - acc: 0.6913 - val_loss: 0.7434 - val_acc: 0.7166\n",
      "Epoch 10/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7799 - acc: 0.6993 - val_loss: 0.8334 - val_acc: 0.6652\n",
      "Epoch 11/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7706 - acc: 0.7031 - val_loss: 0.7431 - val_acc: 0.7178\n",
      "Epoch 12/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7636 - acc: 0.7081 - val_loss: 0.7339 - val_acc: 0.7200\n",
      "Epoch 13/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7582 - acc: 0.7122 - val_loss: 0.7498 - val_acc: 0.7095\n",
      "Epoch 14/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7403 - acc: 0.7177 - val_loss: 0.7476 - val_acc: 0.7199\n",
      "Epoch 15/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7357 - acc: 0.7215 - val_loss: 0.7254 - val_acc: 0.7190\n",
      "Epoch 16/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7329 - acc: 0.7224 - val_loss: 0.7317 - val_acc: 0.7211\n",
      "Epoch 17/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7212 - acc: 0.7224 - val_loss: 0.7103 - val_acc: 0.7277\n",
      "Epoch 18/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7152 - acc: 0.7311 - val_loss: 0.7753 - val_acc: 0.7031\n",
      "Epoch 19/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7124 - acc: 0.7305 - val_loss: 0.6927 - val_acc: 0.7328\n",
      "Epoch 20/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7106 - acc: 0.7278 - val_loss: 0.7666 - val_acc: 0.6995\n",
      "Epoch 21/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.7031 - acc: 0.7344 - val_loss: 0.7352 - val_acc: 0.7242\n",
      "Epoch 22/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6990 - acc: 0.7311 - val_loss: 0.6872 - val_acc: 0.7404\n",
      "Epoch 23/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6940 - acc: 0.7380 - val_loss: 0.6942 - val_acc: 0.7342\n",
      "Epoch 24/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6928 - acc: 0.7370 - val_loss: 0.7231 - val_acc: 0.7228\n",
      "Epoch 25/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6830 - acc: 0.7430 - val_loss: 0.6844 - val_acc: 0.7390\n",
      "Epoch 26/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6807 - acc: 0.7416 - val_loss: 0.7430 - val_acc: 0.7188\n",
      "Epoch 27/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6728 - acc: 0.7453 - val_loss: 0.6904 - val_acc: 0.7307\n",
      "Epoch 28/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6759 - acc: 0.7482 - val_loss: 0.6815 - val_acc: 0.7397\n",
      "Epoch 29/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6651 - acc: 0.7475 - val_loss: 0.7536 - val_acc: 0.7143\n",
      "Epoch 30/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6616 - acc: 0.7500 - val_loss: 0.6832 - val_acc: 0.7416\n",
      "Epoch 31/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6610 - acc: 0.7503 - val_loss: 0.7305 - val_acc: 0.7244\n",
      "Epoch 32/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6581 - acc: 0.7515 - val_loss: 0.7385 - val_acc: 0.7193\n",
      "Epoch 33/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6598 - acc: 0.7503 - val_loss: 0.7646 - val_acc: 0.7103\n",
      "Epoch 34/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6540 - acc: 0.7543 - val_loss: 0.7363 - val_acc: 0.7185\n",
      "Epoch 35/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6527 - acc: 0.7526 - val_loss: 0.7372 - val_acc: 0.7196\n",
      "Epoch 36/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6454 - acc: 0.7560 - val_loss: 0.7022 - val_acc: 0.7373\n",
      "Epoch 37/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6438 - acc: 0.7553 - val_loss: 0.6823 - val_acc: 0.7413\n",
      "Epoch 38/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6425 - acc: 0.7597 - val_loss: 0.6838 - val_acc: 0.7411\n",
      "Epoch 39/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6433 - acc: 0.7617 - val_loss: 0.6683 - val_acc: 0.7486\n",
      "Epoch 40/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6337 - acc: 0.7645 - val_loss: 0.6861 - val_acc: 0.7443\n",
      "Epoch 41/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6322 - acc: 0.7645 - val_loss: 0.6939 - val_acc: 0.7427\n",
      "Epoch 42/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6323 - acc: 0.7639 - val_loss: 0.6790 - val_acc: 0.7419\n",
      "Epoch 43/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6260 - acc: 0.7664 - val_loss: 0.7214 - val_acc: 0.7199\n",
      "Epoch 44/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6248 - acc: 0.7674 - val_loss: 0.6788 - val_acc: 0.7444\n",
      "Epoch 45/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6175 - acc: 0.7685 - val_loss: 0.7664 - val_acc: 0.7123\n",
      "Epoch 46/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.6185 - acc: 0.7681 - val_loss: 0.7336 - val_acc: 0.7178\n",
      "Epoch 47/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6148 - acc: 0.7724 - val_loss: 0.7152 - val_acc: 0.7389\n",
      "Epoch 48/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6092 - acc: 0.7707 - val_loss: 0.7556 - val_acc: 0.7166\n",
      "Epoch 49/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6107 - acc: 0.7738 - val_loss: 0.7083 - val_acc: 0.7409\n",
      "Epoch 50/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6073 - acc: 0.7728 - val_loss: 0.6659 - val_acc: 0.7497\n",
      "Epoch 51/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6045 - acc: 0.7763 - val_loss: 0.7489 - val_acc: 0.7251\n",
      "Epoch 52/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6064 - acc: 0.7760 - val_loss: 0.6874 - val_acc: 0.7429\n",
      "Epoch 53/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.6042 - acc: 0.7768 - val_loss: 0.7234 - val_acc: 0.7417\n",
      "Epoch 54/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5966 - acc: 0.7775 - val_loss: 0.6648 - val_acc: 0.7454\n",
      "Epoch 55/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.6013 - acc: 0.7758 - val_loss: 0.7323 - val_acc: 0.7380\n",
      "Epoch 56/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5936 - acc: 0.7787 - val_loss: 0.7731 - val_acc: 0.7257\n",
      "Epoch 57/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5872 - acc: 0.7821 - val_loss: 0.7380 - val_acc: 0.7378\n",
      "Epoch 58/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5914 - acc: 0.7843 - val_loss: 0.6748 - val_acc: 0.7478\n",
      "Epoch 59/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5876 - acc: 0.7816 - val_loss: 0.7201 - val_acc: 0.7407\n",
      "Epoch 60/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5852 - acc: 0.7834 - val_loss: 0.6833 - val_acc: 0.7428\n",
      "Epoch 61/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5874 - acc: 0.7847 - val_loss: 0.6851 - val_acc: 0.7442\n",
      "Epoch 62/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5818 - acc: 0.7821 - val_loss: 0.6844 - val_acc: 0.7478\n",
      "Epoch 63/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5799 - acc: 0.7863 - val_loss: 0.6887 - val_acc: 0.7404\n",
      "Epoch 64/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5769 - acc: 0.7857 - val_loss: 0.6642 - val_acc: 0.7501\n",
      "Epoch 65/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5681 - acc: 0.7878 - val_loss: 0.7134 - val_acc: 0.7373\n",
      "Epoch 66/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5721 - acc: 0.7896 - val_loss: 0.7115 - val_acc: 0.7373\n",
      "Epoch 67/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5598 - acc: 0.7919 - val_loss: 0.7141 - val_acc: 0.7401\n",
      "Epoch 68/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5610 - acc: 0.7930 - val_loss: 0.7007 - val_acc: 0.7456\n",
      "Epoch 69/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5639 - acc: 0.7899 - val_loss: 0.6923 - val_acc: 0.7425\n",
      "Epoch 70/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5587 - acc: 0.7950 - val_loss: 0.6924 - val_acc: 0.7473\n",
      "Epoch 71/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5611 - acc: 0.7924 - val_loss: 0.6885 - val_acc: 0.7451\n",
      "Epoch 72/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5566 - acc: 0.7924 - val_loss: 0.6889 - val_acc: 0.7477\n",
      "Epoch 73/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5583 - acc: 0.7952 - val_loss: 0.7007 - val_acc: 0.7393\n",
      "Epoch 74/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5526 - acc: 0.7977 - val_loss: 0.7481 - val_acc: 0.7274\n",
      "Epoch 75/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5503 - acc: 0.7970 - val_loss: 0.6823 - val_acc: 0.7454\n",
      "Epoch 76/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5407 - acc: 0.8001 - val_loss: 0.7077 - val_acc: 0.7479\n",
      "Epoch 77/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5459 - acc: 0.7989 - val_loss: 0.7661 - val_acc: 0.7353\n",
      "Epoch 78/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5440 - acc: 0.8025 - val_loss: 0.7781 - val_acc: 0.7274\n",
      "Epoch 79/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5489 - acc: 0.7970 - val_loss: 0.7633 - val_acc: 0.7308\n",
      "Epoch 80/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5408 - acc: 0.8033 - val_loss: 0.6802 - val_acc: 0.7452\n",
      "Epoch 81/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5377 - acc: 0.8003 - val_loss: 0.7793 - val_acc: 0.7196\n",
      "Epoch 82/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5371 - acc: 0.8041 - val_loss: 0.7978 - val_acc: 0.7170\n",
      "Epoch 83/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5364 - acc: 0.8031 - val_loss: 0.7764 - val_acc: 0.7176\n",
      "Epoch 84/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5291 - acc: 0.8047 - val_loss: 0.7367 - val_acc: 0.7454\n",
      "Epoch 85/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5340 - acc: 0.8065 - val_loss: 0.7368 - val_acc: 0.7354\n",
      "Epoch 86/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5289 - acc: 0.8087 - val_loss: 0.7204 - val_acc: 0.7512\n",
      "Epoch 87/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5292 - acc: 0.8063 - val_loss: 0.7177 - val_acc: 0.7456\n",
      "Epoch 88/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5168 - acc: 0.8103 - val_loss: 0.7291 - val_acc: 0.7340\n",
      "Epoch 89/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5292 - acc: 0.8108 - val_loss: 0.7034 - val_acc: 0.7396\n",
      "Epoch 90/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5254 - acc: 0.8099 - val_loss: 0.7562 - val_acc: 0.7273\n",
      "Epoch 91/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5204 - acc: 0.8128 - val_loss: 0.7400 - val_acc: 0.7392\n",
      "Epoch 92/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5156 - acc: 0.8125 - val_loss: 0.7798 - val_acc: 0.7244\n",
      "Epoch 93/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5171 - acc: 0.8131 - val_loss: 0.7015 - val_acc: 0.7463\n",
      "Epoch 94/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5098 - acc: 0.8200 - val_loss: 0.7160 - val_acc: 0.7567\n",
      "Epoch 95/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5141 - acc: 0.8150 - val_loss: 0.7045 - val_acc: 0.7428\n",
      "Epoch 96/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5115 - acc: 0.8171 - val_loss: 0.7292 - val_acc: 0.7421\n",
      "Epoch 97/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5124 - acc: 0.8190 - val_loss: 0.7676 - val_acc: 0.7273\n",
      "Epoch 98/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5117 - acc: 0.8181 - val_loss: 0.7172 - val_acc: 0.7452\n",
      "Epoch 99/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5052 - acc: 0.8175 - val_loss: 0.7545 - val_acc: 0.7354\n",
      "Epoch 100/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.5079 - acc: 0.8182 - val_loss: 0.7981 - val_acc: 0.7200\n",
      "Epoch 101/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5020 - acc: 0.8204 - val_loss: 0.7074 - val_acc: 0.7501\n",
      "Epoch 102/200\n",
      "15037/15037 [==============================] - 2s - loss: 0.4962 - acc: 0.8193 - val_loss: 0.7331 - val_acc: 0.7423\n",
      "Epoch 103/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.5028 - acc: 0.8205 - val_loss: 0.7620 - val_acc: 0.7392\n",
      "Epoch 104/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.4995 - acc: 0.8212 - val_loss: 0.7253 - val_acc: 0.7397\n",
      "Epoch 105/200\n",
      "15037/15037 [==============================] - 3s - loss: 0.4958 - acc: 0.8210 - val_loss: 0.7195 - val_acc: 0.7405\n",
      "Epoch 106/200\n",
      "   32/15037 [..............................] - ETA: 9s - loss: 0.6459 - acc: 0.7500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a240768e31b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m               shuffle=True)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using real-time data augmentation.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.0,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.0,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(X_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a70009143d02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.72940465018899558, 0.74915620372799774]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
